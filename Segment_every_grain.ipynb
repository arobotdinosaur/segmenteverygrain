{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95a8f02b",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2ebc518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:42:08.008307Z",
     "iopub.status.busy": "2025-09-08T17:42:08.007656Z",
     "iopub.status.idle": "2025-09-08T17:42:13.269139Z",
     "shell.execute_reply": "2025-09-08T17:42:13.268766Z",
     "shell.execute_reply.started": "2025-09-08T17:42:08.008250Z"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import segment_anything\n",
    "import segmenteverygrain as seg\n",
    "import segmenteverygrain.interactions as si\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f474ac20",
   "metadata": {},
   "source": [
    "## Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe1bd2bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:43:15.618113Z",
     "iopub.status.busy": "2025-09-08T17:43:15.617820Z",
     "iopub.status.idle": "2025-09-08T17:43:16.359902Z",
     "shell.execute_reply": "2025-09-08T17:43:16.359574Z",
     "shell.execute_reply.started": "2025-09-08T17:43:15.618098Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load UNET model\n",
    "unet = keras.saving.load_model(\n",
    "    #\"./models/seg_model.keras\",\n",
    "    \"./examples/unet_training2/second.keras\",\n",
    "    custom_objects={\"weighted_crossentropy\": seg.weighted_crossentropy},\n",
    ")\n",
    "\n",
    "# Download SAM model (only downloads it if it does not exist)\n",
    "if not os.path.exists(\"./models/sam_vit_h_4b8939.pth\"):\n",
    "    import urllib.request\n",
    "    url = \"https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\"\n",
    "    urllib.request.urlretrieve(url, \"./models/sam_vit_h_4b8939.pth\")\n",
    "\n",
    "# Load SAM\n",
    "fname = './models/sam_vit_h_4b8939.pth'\n",
    "sam = segment_anything.sam_model_registry['default'](checkpoint=fname)\n",
    "predictor = segment_anything.SamPredictor(sam)\n",
    "#predictor.set_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1dfc6",
   "metadata": {},
   "source": [
    "## Run segmentation\n",
    "\n",
    "Grains are supposed to be well defined in the image; e.g., if a grain consists of only a few pixels, it is unlikely to be detected.\n",
    "\n",
    "The segmentation can take a few minutes even for medium-sized images. Images with ~2000 pixels along their largest dimension are a good start and allow the user to get an idea about how well the segmentation works.\n",
    "\n",
    "If you have a much larger image, see the section **\"Run segmentation on large image\"** at the end of the notebook. Running the `predict_large_image` function takes a lot longer (e.g., several hours), but it is possible to analyze very large images with tens of thousands of grains.\n",
    "\n",
    "Image used below is available from [here](https://github.com/zsylvester/segmenteverygrain/blob/main/examples/barton_creek/barton_creek_image.jpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94bf3f94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:45:19.692513Z",
     "iopub.status.busy": "2025-09-08T17:45:19.692155Z",
     "iopub.status.idle": "2025-09-08T17:45:27.511704Z",
     "shell.execute_reply": "2025-09-08T17:45:27.511357Z",
     "shell.execute_reply.started": "2025-09-08T17:45:19.692486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmenting image tiles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:03<00:00,  1.68it/s]\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# replace this with the path to your image:\n",
    "#fname = \"./examples/barton_creek/barton_creek_image.jpg\"\n",
    "fname = \"/Volumes/Blob/segmenteverygrain/20250828_Alumina_SEM (1)/prac7_etched_004.tif\" \n",
    "\n",
    "#gray_img = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "#rgb_image = cv2.cvtColor(gray_img, cv2.COLOR_GRAY2RGB)#\n",
    "\n",
    "#path_no_extension, _ = os.path.splitext(fname)\n",
    "#fname = path_no_extension + \".png\"\n",
    "#cv2.imwrite(fname, rgb_image)\n",
    "\n",
    "image = si.load_image(fname)\n",
    "predictor.set_image(image)\n",
    "image_pred = seg.predict_image(image, unet, I=256)\n",
    "\n",
    "# decreasing the 'dbs_max_dist' parameter results in more SAM prompts\n",
    "# (and longer processing times):\n",
    "labels, coords = seg.label_grains(image, image_pred, dbs_max_dist=10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c091d4c",
   "metadata": {},
   "source": [
    "Use the figure created in the next cell to check the quality of the Unet labeling (sometimes it doesn't work at all) and the distribution of SAM prompts (= black dots). If the Unet prediction is of poor quality, it is a good idea to create some training data and fine tune the base model so that it works better with the images of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e031a13f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:47:29.299086Z",
     "iopub.status.busy": "2025-09-08T17:47:29.298133Z",
     "iopub.status.idle": "2025-09-08T17:47:29.661768Z",
     "shell.execute_reply": "2025-09-08T17:47:29.661114Z",
     "shell.execute_reply.started": "2025-09-08T17:47:29.299021Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "ax.imshow(image_pred)\n",
    "plt.scatter(np.array(coords)[:, 0], np.array(coords)[:, 1], c=\"k\")\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bcedac-6a3f-4f1d-97a9-b167fa14994c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:51:03.808049Z",
     "iopub.status.busy": "2025-09-08T17:51:03.807680Z",
     "iopub.status.idle": "2025-09-08T17:52:39.560648Z",
     "shell.execute_reply": "2025-09-08T17:52:39.560319Z",
     "shell.execute_reply.started": "2025-09-08T17:51:03.808020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating masks using SAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:01<00:00, 16.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding overlapping polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:00, 210.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating labeled image...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:00<00:00, 201.83it/s]\n"
     ]
    }
   ],
   "source": [
    "# SAM segmentation, using the point prompts from the Unet:\n",
    "all_grains, labels, mask_all, grain_data, fig, ax = seg.sam_segmentation(\n",
    "    sam, image, image_pred, coords, labels,\n",
    "    min_area=300.0,\n",
    "    plot_image=True,\n",
    "    remove_edge_grains=False,\n",
    "    remove_large_objects=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1adaf-54f4-4aee-8598-47de9f3d2455",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:55:10.204658Z",
     "iopub.status.busy": "2025-09-08T17:55:10.204160Z",
     "iopub.status.idle": "2025-09-08T17:55:10.618821Z",
     "shell.execute_reply": "2025-09-08T17:55:10.618481Z",
     "shell.execute_reply.started": "2025-09-08T17:55:10.204625Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'examples/auto_detection/barton_creek_grains.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save SAM image\u001b[39;00m\n\u001b[1;32m      2\u001b[0m out_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexamples/auto_detection/barton_creek\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_fn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_grains.jpg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_inches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_inches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniforge3/envs/grains/lib/python3.9/site-packages/matplotlib/figure.py:3395\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3393\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3394\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[0;32m-> 3395\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/grains/lib/python3.9/site-packages/matplotlib/backends/backend_qtagg.py:75\u001b[0m, in \u001b[0;36mFigureCanvasQTAgg.print_figure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprint_figure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# In some cases, Qt will itself trigger a paint event after closing the file\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# save dialog. When that happens, we need to be sure that the internal canvas is\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# re-drawn. However, if the user is using an automatically-chosen Qt backend but\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# saving with a different backend (such as pgf), we do not want to trigger a\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# full draw in Qt, so just set the flag for next time.\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_draw_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/grains/lib/python3.9/site-packages/matplotlib/backend_bases.py:2204\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2201\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2202\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2203\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2204\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2206\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2207\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2208\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[0;32m~/miniforge3/envs/grains/lib/python3.9/site-packages/matplotlib/backend_bases.py:2054\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2051\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2052\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2053\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2054\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[0;32m~/miniforge3/envs/grains/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:513\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_jpg\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprint_jpg\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;66;03m# savefig() has already applied savefig.facecolor; we now set it to\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# white to make imsave() blend semi-transparent figures against an\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;66;03m# assumed white background.\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m mpl\u001b[38;5;241m.\u001b[39mrc_context({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msavefig.facecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhite\u001b[39m\u001b[38;5;124m\"\u001b[39m}):\n\u001b[0;32m--> 513\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/grains/lib/python3.9/site-packages/matplotlib/backends/backend_agg.py:445\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    444\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 445\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/grains/lib/python3.9/site-packages/matplotlib/image.py:1676\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1674\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1675\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1676\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/grains/lib/python3.9/site-packages/PIL/Image.py:2583\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2581\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2582\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2583\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2585\u001b[0m     fp \u001b[38;5;241m=\u001b[39m cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'examples/auto_detection/barton_creek_grains.jpg'"
     ]
    }
   ],
   "source": [
    "# Save SAM image\n",
    "out_fn = 'examples/auto_detection/barton_creek'\n",
    "fig.savefig(out_fn + '_grains.jpg', bbox_inches='tight', pad_inches=0)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dcc0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test of automatic mask generation\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "\n",
    "#sam_checkpoint = \"./models/sam_vit_h_4b8939.pth\"\n",
    "#model_type = \"vit_h\"\n",
    "\n",
    "#sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd551e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8830dd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = mask_generator.generate(image)\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(image)\n",
    "show_anns(masks)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb25eaa-c9c2-4e4f-b0b3-61dfbf8219b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:55:38.112664Z",
     "iopub.status.busy": "2025-09-08T17:55:38.112237Z",
     "iopub.status.idle": "2025-09-08T17:55:38.115860Z",
     "shell.execute_reply": "2025-09-08T17:55:38.115106Z",
     "shell.execute_reply.started": "2025-09-08T17:55:38.112630Z"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f3d4583-7c13-4a61-a47f-bc1c4c475066",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:56:20.445041Z",
     "iopub.status.busy": "2025-09-08T17:56:20.444456Z",
     "iopub.status.idle": "2025-09-08T17:56:20.813239Z",
     "shell.execute_reply": "2025-09-08T17:56:20.812637Z",
     "shell.execute_reply.started": "2025-09-08T17:56:20.444989Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring detected grains: 100%|██████████| 111/111 [00:00<00:00, 1344.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract results\n",
    "grains = si.polygons_to_grains(all_grains, image=image)\n",
    "for g in tqdm(grains, desc='Measuring detected grains'):\n",
    "    g.measure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cc3023-f325-4fa7-9ab6-e6c451f5d27a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:56:49.579595Z",
     "iopub.status.busy": "2025-09-08T17:56:49.579362Z",
     "iopub.status.idle": "2025-09-08T17:56:49.583444Z",
     "shell.execute_reply": "2025-09-08T17:56:49.582881Z",
     "shell.execute_reply.started": "2025-09-08T17:56:49.579574Z"
    }
   },
   "source": [
    "The following results are then saved to the location specified in `out_fn`:\n",
    "- Grain shapes, for use elsewhere (geojson)\n",
    "- Summary data, presenting measurements for each detected grain (csv)\n",
    "- Summary histogram, representing major/minor axes of detected grains (jpg)\n",
    "- Mask representations of the detected grains, in both computer-readable (png, 0-1) and human-readable (jpg, 0-255) formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d533c215-4e42-4166-8edd-6d01279c9399",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T17:58:29.806506Z",
     "iopub.status.busy": "2025-09-08T17:58:29.806113Z",
     "iopub.status.idle": "2025-09-08T17:58:31.947627Z",
     "shell.execute_reply": "2025-09-08T17:58:31.947305Z",
     "shell.execute_reply.started": "2025-09-08T17:58:29.806475Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:00<00:00, 300.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# re-plot results if needed\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "seg.plot_image_w_colorful_grains(image, all_grains, ax, cmap=\"Paired\", plot_image=True)\n",
    "seg.plot_grain_axes_and_centroids(all_grains, labels, ax, linewidth=1, markersize=10)\n",
    "plt.xlim([0, np.shape(image)[1]])\n",
    "plt.ylim([np.shape(image)[0], 0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e8bdc-afa7-40af-b997-0fee343605a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T18:03:31.862782Z",
     "iopub.status.busy": "2025-09-08T18:03:31.862036Z",
     "iopub.status.idle": "2025-09-08T18:03:31.870925Z",
     "shell.execute_reply": "2025-09-08T18:03:31.869174Z",
     "shell.execute_reply.started": "2025-09-08T18:03:31.862721Z"
    }
   },
   "source": [
    "Run this cell and then click (left mouse button) on one end of the scale bar in the image and click (right mouse button) on the other end of the scale bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8296001-9b85-4414-a0f5-a0b0fab4fd81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T19:21:37.993293Z",
     "iopub.status.busy": "2025-09-08T19:21:37.992827Z",
     "iopub.status.idle": "2025-09-08T19:21:37.997280Z",
     "shell.execute_reply": "2025-09-08T19:21:37.996530Z",
     "shell.execute_reply.started": "2025-09-08T19:21:37.993257Z"
    }
   },
   "outputs": [],
   "source": [
    "cid = fig.canvas.mpl_connect(\n",
    "    \"button_press_event\", lambda event: seg.click_for_scale(event, ax)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa1fa6-fab3-4bde-859e-bd081071cd25",
   "metadata": {},
   "source": [
    "If `px_per_m` is 1, then the summary data and histogram will be in pixels. If the ratio of pixels to meters is known, set `px_per_m` in order to save them in meters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c36ac7b6-fed3-4451-9532-ab0c5b76abe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T18:00:32.069460Z",
     "iopub.status.busy": "2025-09-08T18:00:32.069097Z",
     "iopub.status.idle": "2025-09-08T18:00:33.692809Z",
     "shell.execute_reply": "2025-09-08T18:00:33.692475Z",
     "shell.execute_reply.started": "2025-09-08T18:00:32.069431Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save results\n",
    "px_per_m = 3711.9    # 371.19 pixels / 10 cm (scale bar on photo)\n",
    "out_fn = 'examples/auto_detection/barton_creek'\n",
    "# Grain shapes\n",
    "si.save_grains(out_fn + '_grains.geojson', grains)\n",
    "# Summary data\n",
    "summary = si.save_summary(out_fn + '_summary.csv', grains, px_per_m=px_per_m)\n",
    "# Summary histogram\n",
    "si.save_histogram(out_fn + '_summary.jpg', summary=summary)\n",
    "# Training mask\n",
    "si.save_mask(out_fn + '_mask.png', grains, image, scale=False)\n",
    "si.save_mask(out_fn + '_mask2.jpg', grains, image, scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0efc91-06a3-4f74-a03c-1075f0883165",
   "metadata": {},
   "source": [
    "## Delete, merge, and add grains\n",
    "\n",
    "Open and run the [`interactive_edit.ipynb`]('intercative_edit.ipynb') notebook to refine the results and generate training data. This new approach is more user friendly and faster than the previous implementation; thanks to [Dave Matthews](https://github.com/dirtbirb) for contributing the `segmenteverygrain.interactions` module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db7f2b-7718-4466-a1d8-41aa3d3d0803",
   "metadata": {},
   "source": [
    "## Run segmentation on large image\n",
    "In this case 'fname' points to an image that is larger than a few megapixels and has thousands of grains.\n",
    "The 'predict_large_image' function breaks the input image into smaller patches and it runs the segmentation process on each patch.\n",
    "\n",
    "The image used below (from [Mair et al., 2022, Earth Surface Dynamics](https://esurf.copernicus.org/articles/10/953/2022/)) is available [here](https://github.com/zsylvester/segmenteverygrain/blob/main/examples/mair_et_al_L2_DJI_0382/mair_et_al_L2_DJI_0382_image.jpg)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90eed72b-4cad-409a-b7bf-bbad0e5dfa74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T18:05:05.382594Z",
     "iopub.status.busy": "2025-09-08T18:05:05.382049Z",
     "iopub.status.idle": "2025-09-08T18:25:02.808080Z",
     "shell.execute_reply": "2025-09-08T18:25:02.807764Z",
     "shell.execute_reply.started": "2025-09-08T18:05:05.382548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmenting image tiles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:03<00:00,  2.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating masks using SAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2804/2804 [03:06<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding overlapping polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2537it [00:04, 570.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1021/1021 [00:24<00:00, 42.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating labeled image...\n",
      "processed patch #1 out of 6 patches\n",
      "segmenting image tiles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:03<00:00,  2.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:03<00:00,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating masks using SAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1996/1996 [02:12<00:00, 15.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding overlapping polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1766it [00:04, 402.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 666/666 [00:14<00:00, 47.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating labeled image...\n",
      "processed patch #2 out of 6 patches\n",
      "segmenting image tiles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:03<00:00,  2.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:03<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating masks using SAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1757/1757 [01:56<00:00, 15.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding overlapping polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1545it [00:04, 367.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 581/581 [00:11<00:00, 51.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating labeled image...\n",
      "processed patch #3 out of 6 patches\n",
      "segmenting image tiles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:03<00:00,  2.47it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:03<00:00,  2.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating masks using SAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 3173/3173 [03:24<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding overlapping polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2941it [00:03, 840.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:32<00:00, 37.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating labeled image...\n",
      "processed patch #4 out of 6 patches\n",
      "segmenting image tiles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:03<00:00,  2.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:03<00:00,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating masks using SAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 2041/2041 [02:22<00:00, 14.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding overlapping polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1811it [00:04, 439.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 693/693 [00:15<00:00, 44.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating labeled image...\n",
      "processed patch #5 out of 6 patches\n",
      "segmenting image tiles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:03<00:00,  2.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:03<00:00,  2.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating masks using SAM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1662/1662 [01:46<00:00, 15.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding overlapping polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1436it [00:04, 323.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finding best polygons...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 519/519 [00:10<00:00, 47.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating labeled image...\n",
      "processed patch #6 out of 6 patches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4753it [00:02, 2302.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 331/331 [00:54<00:00,  6.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None  # needed if working with very large images\n",
    "fname = \"./examples/mair_et_al_L2_DJI_0382/mair_et_al_L2_DJI_0382_image.jpg\"\n",
    "all_grains, image_pred, all_coords = seg.predict_large_image(\n",
    "    fname, unet, sam, min_area=400.0, patch_size=2000, overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1e52b04-e54e-44e6-8061-b8d0c0c76970",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T18:30:29.331512Z",
     "iopub.status.busy": "2025-09-08T18:30:29.331116Z",
     "iopub.status.idle": "2025-09-08T18:30:43.766419Z",
     "shell.execute_reply": "2025-09-08T18:30:43.766070Z",
     "shell.execute_reply.started": "2025-09-08T18:30:29.331482Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 4399/4399 [00:13<00:00, 315.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# plot results\n",
    "image = si.load_image(fname)\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "seg.plot_image_w_colorful_grains(image, all_grains, ax, cmap=\"Paired\")\n",
    "plt.axis(\"equal\")\n",
    "plt.xlim([0, np.shape(image)[1]])\n",
    "plt.ylim([np.shape(image)[0], 0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e247494-f1af-4ece-ac22-78055cf3f110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T19:28:54.968459Z",
     "iopub.status.busy": "2025-09-08T19:28:54.968084Z",
     "iopub.status.idle": "2025-09-08T19:28:54.973326Z",
     "shell.execute_reply": "2025-09-08T19:28:54.972395Z",
     "shell.execute_reply.started": "2025-09-08T19:28:54.968431Z"
    }
   },
   "source": [
    "Run this cell and then click (left mouse button) on one end of the scale bar in the image and click (right mouse button) on the other end of the scale bar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f73f59f-5b8d-4807-981a-2e36f103ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cid = fig.canvas.mpl_connect(\n",
    "    \"button_press_event\", lambda event: seg.click_for_scale(event, ax)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5604c1ea-0a3a-4c3d-b46a-ec4a6bc24f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T19:27:19.037229Z",
     "iopub.status.busy": "2025-09-08T19:27:19.036716Z",
     "iopub.status.idle": "2025-09-08T19:27:21.449718Z",
     "shell.execute_reply": "2025-09-08T19:27:21.449377Z",
     "shell.execute_reply.started": "2025-09-08T19:27:19.037208Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Measuring detected grains: 100%|██████████████████████████████████████████████████████████████████| 4399/4399 [00:02<00:00, 2142.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract results\n",
    "grains = si.polygons_to_grains(all_grains, image=image)\n",
    "for g in tqdm(grains, desc='Measuring detected grains'):\n",
    "    g.measure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fddef05b-a4d9-4945-875e-b16b36f3a774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-08T19:27:27.216309Z",
     "iopub.status.busy": "2025-09-08T19:27:27.215964Z",
     "iopub.status.idle": "2025-09-08T19:27:38.547960Z",
     "shell.execute_reply": "2025-09-08T19:27:38.547584Z",
     "shell.execute_reply.started": "2025-09-08T19:27:27.216283Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save results\n",
    "px_per_m = 1812  # 181.2 pixels / 10 cm (scale bar on photo)\n",
    "out_fn = 'examples/auto_detection/mair_et_al'\n",
    "# Grain shapes\n",
    "si.save_grains(out_fn + '_grains.geojson', grains)\n",
    "# Summary data\n",
    "summary = si.save_summary(out_fn + '_summary.csv', grains, px_per_m=px_per_m)\n",
    "# Summary histogram\n",
    "si.save_histogram(out_fn + '_summary.jpg', summary=summary)\n",
    "# Training mask\n",
    "si.save_mask(out_fn + '_mask.png', grains, image, scale=False)\n",
    "si.save_mask(out_fn + '_mask2.jpg', grains, image, scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25703e4-2a4e-4e98-aa49-ff9b816b2ec0",
   "metadata": {},
   "source": [
    "### Finetuning the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f01735f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]]\n",
      "[[[1 1 1]\n",
      "  [1 1 1]\n",
      "  [1 1 1]\n",
      "  ...\n",
      "  [1 1 1]\n",
      "  [1 1 1]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[1 1 1]\n",
      "  [1 1 1]\n",
      "  [1 1 1]\n",
      "  ...\n",
      "  [1 1 1]\n",
      "  [1 1 1]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[1 1 1]\n",
      "  [1 1 1]\n",
      "  [1 1 1]\n",
      "  ...\n",
      "  [1 1 1]\n",
      "  [1 1 1]\n",
      "  [1 1 1]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1 1 1]\n",
      "  [1 1 1]\n",
      "  [1 1 1]\n",
      "  ...\n",
      "  [1 1 1]\n",
      "  [1 1 1]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[1 1 1]\n",
      "  [1 1 1]\n",
      "  [1 1 1]\n",
      "  ...\n",
      "  [1 1 1]\n",
      "  [1 1 1]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[1 1 1]\n",
      "  [1 1 1]\n",
      "  [1 1 1]\n",
      "  ...\n",
      "  [1 1 1]\n",
      "  [1 1 1]\n",
      "  [1 1 1]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualize mask\n",
    "#mask = cv2.imread(\"examples/barton_creek/barton_creek_image_mask.png\", cv2.IMREAD_GRAYSCALE)\n",
    "#mask = cv2.imread(\"examples/unet_training/Masks_and_images/OffshoreMiocene_20_1_mask.png\", cv2.IMREAD_GRAYSCALE)\n",
    "#mask = cv2.imread(\"examples/torrey_pines_beach/torrey_pines_beach_mask.png\", cv2.IMREAD_GRAYSCALE)\n",
    "mask = cv2.imread(\"examples/unet_training2/Masks_and_images/prac7_etched_099_m.tif\")\n",
    "#mask=mask/255\n",
    "print(mask)\n",
    "plt.imshow(mask, cmap=\"gray\", vmin=0, vmax=1)\n",
    "# Ensure binary values (0 or 1)\n",
    "mask_binary = (mask > 127).astype(np.uint8)\n",
    "print(mask_binary)\n",
    "# Save back in correct format\n",
    "cv2.imwrite(\"examples/unet_training2/Masks_and_images/mask_binary.tif\", mask_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "396f62c8-be0f-47fe-b660-2c55e2d51d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# patchify images and masks\n",
    "input_dir = \"./examples/unet_training2/Masks_and_images/\"  # the input directory should contain files with 'image' and 'mask' in their filenames\n",
    "patch_dir = (\n",
    "    \"./examples/unet_training2/\"  # a directory called \"Patches\" will be created here\n",
    ")\n",
    "image_dir, mask_dir = seg.patchify_training_data(input_dir, patch_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05f98137-2dfd-4b88-8dc5-e4e79fa343ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training, validation, and test datasets\n",
    "train_dataset, val_dataset, test_dataset = seg.create_train_val_test_data(\n",
    "    image_dir, mask_dir, augmentation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43650ad9-c2e5-4fc2-856f-4f39b8f1d9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.4866 - loss: 0.9947 - val_accuracy: 0.4663 - val_loss: 1.0233\n",
      "Epoch 2/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.5480 - loss: 0.9338 - val_accuracy: 0.5474 - val_loss: 0.9395\n",
      "Epoch 3/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5667 - loss: 0.9152 - val_accuracy: 0.5816 - val_loss: 0.9047\n",
      "Epoch 4/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5972 - loss: 0.8848 - val_accuracy: 0.6368 - val_loss: 0.8477\n",
      "Epoch 5/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.6161 - loss: 0.8659 - val_accuracy: 0.7041 - val_loss: 0.7776\n",
      "Epoch 6/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.6406 - loss: 0.8407 - val_accuracy: 0.7580 - val_loss: 0.7223\n",
      "Epoch 7/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.6719 - loss: 0.8083 - val_accuracy: 0.7786 - val_loss: 0.7020\n",
      "Epoch 8/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.6999 - loss: 0.7796 - val_accuracy: 0.8056 - val_loss: 0.6744\n",
      "Epoch 9/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.7417 - loss: 0.7375 - val_accuracy: 0.8393 - val_loss: 0.6401\n",
      "Epoch 10/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.7667 - loss: 0.7143 - val_accuracy: 0.8534 - val_loss: 0.6246\n",
      "Epoch 11/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.7968 - loss: 0.6912 - val_accuracy: 0.8566 - val_loss: 0.6206\n",
      "Epoch 12/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8141 - loss: 0.6747 - val_accuracy: 0.8582 - val_loss: 0.6189\n",
      "Epoch 13/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8287 - loss: 0.6606 - val_accuracy: 0.8592 - val_loss: 0.6179\n",
      "Epoch 14/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8387 - loss: 0.6505 - val_accuracy: 0.8600 - val_loss: 0.6170\n",
      "Epoch 15/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8484 - loss: 0.6425 - val_accuracy: 0.8611 - val_loss: 0.6159\n",
      "Epoch 16/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8573 - loss: 0.6326 - val_accuracy: 0.8633 - val_loss: 0.6137\n",
      "Epoch 17/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8638 - loss: 0.6243 - val_accuracy: 0.8664 - val_loss: 0.6104\n",
      "Epoch 18/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8672 - loss: 0.6199 - val_accuracy: 0.8696 - val_loss: 0.6070\n",
      "Epoch 19/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8690 - loss: 0.6163 - val_accuracy: 0.8731 - val_loss: 0.6032\n",
      "Epoch 20/20\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.8720 - loss: 0.6134 - val_accuracy: 0.8756 - val_loss: 0.6006\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 0.8714 - loss: 0.6038\n"
     ]
    }
   ],
   "source": [
    "# load base model weights and train the model with the new data\n",
    "model = seg.create_and_train_model(\n",
    "    train_dataset,\n",
    "    val_dataset,\n",
    "    test_dataset,\n",
    "    model_file=\"./models/seg_model.keras\",\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41375c1f-5f16-496f-b5e8-497626eb89dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save finetuned model as new model (this then can be loaded using \"model = load_model(\"new_model.keras\", custom_objects={'weighted_crossentropy': seg.weighted_crossentropy})\"\n",
    "model.save(\"./examples/unet_training2/second.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grains",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
